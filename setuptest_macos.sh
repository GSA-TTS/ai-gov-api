#!/bin/bash
# Exit immediately if a command exits with a non-zero status.
set -e
# Treat unset variables as an error when substituting.
set -u
# Pipes fail on the first error.
set -o pipefail

# --- Helper Functions ---
info() {
    echo "[INFO] $1"
}
warn() {
    echo "[WARN] $1"
}
error() {
    echo "[ERROR] $1" >&2
    exit 1
}

# Function to check if a command exists
command_exists() {
    command -v "$1" >/dev/null 2>&1
}

# Function to prompt for required variable if not set
prompt_if_unset() {
    local var_name="$1"
    local prompt_message="$2"
    local is_secret_provider_var="$3" # "true" if this is a cloud provider secret
    local use_mocks_flag="${USE_MOCK_PROVIDERS_CHOICE:-true}" # Default to true for mocks

    # Check if the variable is set and not empty using indirect expansion
    if [ -z "${!var_name:-}" ]; then
        if [[ "$use_mocks_flag" == "true" && "$is_secret_provider_var" == "true" ]]; then
            local temp_val_mock
            read -rp "$prompt_message (optional as mocks are enabled, press Enter to skip): " temp_val_mock
            if [ -n "$temp_val_mock" ]; then
                eval "$var_name=\"$temp_val_mock\""
            else
                eval "$var_name=\"\"" # Set to empty if skipped and using mocks
                warn "$var_name not provided, will be empty (mock mode active for providers)."
            fi
        else # Not using mocks OR not a cloud provider secret, so it's required
            local temp_val_live
            read -rp "$prompt_message: " temp_val_live
            if [ -z "$temp_val_live" ]; then
                error "$var_name is required and was not provided."
            fi
            eval "$var_name=\"$temp_val_live\""
        fi
    fi
    export "$var_name" # Export it so it's available for the .env file
}

# --- Sanity Checks & Prerequisites ---
info "Starting AI API Framework setup for macOS..."
if [[ "$(uname)" != "Darwin" ]]; then
    error "This script is intended for macOS only."
fi

# --- Handle Zscaler/corporate proxy certificate ---
info "Checking for Zscaler or other corporate proxies..."
ZSCALER_DETECTED=false
CERT_PATH="" # Initialize CERT_PATH

# Check if Zscaler certificate files exist in the current directory
if [ -f "./zscaler.pem" ] || [ -f "./zscaler.crt" ]; then
    info "Zscaler certificate found locally (./zscaler.pem or ./zscaler.crt)."
    ZSCALER_DETECTED=true

    USER_CERT_DIR="${HOME}/.certificates"
    mkdir -p "${USER_CERT_DIR}"

    if [ -f "./zscaler.pem" ]; then
        cp ./zscaler.pem "${USER_CERT_DIR}/zscaler_aigovapi.pem"
        CERT_PATH="${USER_CERT_DIR}/zscaler_aigovapi.pem"
        info "Copied ./zscaler.pem to ${CERT_PATH}"
    else # Must be .crt
        cp ./zscaler.crt "${USER_CERT_DIR}/zscaler_aigovapi.crt"
        CERT_PATH="${USER_CERT_DIR}/zscaler_aigovapi.crt"
        info "Copied ./zscaler.crt to ${CERT_PATH}"
    fi

    export SSL_CERT_FILE="${CERT_PATH}"
    export REQUESTS_CA_BUNDLE="${CERT_PATH}"
    info "Set SSL_CERT_FILE and REQUESTS_CA_BUNDLE for this session to: ${CERT_PATH}"
else
    info "No local Zscaler certificate (zscaler.pem or zscaler.crt) found in the current directory."
fi

info "Checking for Git..."
if ! command_exists git; then
    warn "Git not found. Please install Git (e.g., via Xcode Command Line Tools: 'xcode-select --install') and clone the repository, then re-run this script from the project root."
    error "Git is required."
else
    info "Git found."
fi

info "Checking for C compiler (needed for some Python packages)..."
if ! command_exists gcc && ! command_exists clang; then
    warn "No C compiler (gcc or clang) found. If Python package installations fail, you may need to install Xcode Command Line Tools ('xcode-select --install')."
else
    info "C compiler (gcc or clang) found."
fi

info "Checking for Docker..."
if ! command_exists docker; then
    warn "Docker not found. Please install Docker Desktop for Mac: https://www.docker.com/products/docker-desktop/"
    error "Docker is required. Please install it and ensure it's running, then re-run the script."
else
    info "Docker found."
    if ! docker info > /dev/null 2>&1; then
        error "Docker daemon is not running. Please start Docker Desktop and re-run the script."
    fi
    info "Docker is running."
fi

# --- Create requirements.txt file if it doesn't exist ---
if [ ! -f "requirements.txt" ]; then
    info "Creating requirements.txt..."
    # Based on project structure and common FastAPI/SQLAlchemy/Cloud SDK needs.
    # psycopg[binary] is used for PostgreSQL with psycopg driver.
    # google-cloud-aiplatform includes vertexai.
    cat > requirements.txt << EOF
# Generated by setup_macos.sh
aioboto3>=14.1.0
alembic>=1.15.1
fastapi>=0.115.11
google-cloud-aiplatform>=1.90.0
# google-generativeai # Removed as vertexai is primary for this project
greenlet>=3.1.1
psycopg[binary]>=3.2.5 # For postgresql+psycopg connection string
pydantic>=2.10.6
pydantic-settings>=2.8.1
sqlalchemy>=2.0.38
structlog>=25.2.0
types-aioboto3>=14.1.0
uvicorn>=0.34.0
# vertexai is part of google-cloud-aiplatform

# Test dependencies
pytest>=8.3.5
pytest-asyncio>=0.26.0
pytest-mock>=3.14.0

# Linter
ruff>=0.9.10
EOF
    info "Created requirements.txt file."
else
    info "requirements.txt already exists. Skipping creation."
fi

# --- Setup Python Environment ---
info "Setting up Python virtual environment..."
if [ -d ".venv" ]; then
    info "Virtual environment '.venv' already exists."
else
    python3 -m venv .venv
    info "Created virtual environment '.venv'."
fi

info "Activating virtual environment..."
source .venv/bin/activate
info "Virtual environment activated."

info "Installing dependencies with pip..."
if [ "$ZSCALER_DETECTED" = "true" ] && [ -n "$CERT_PATH" ]; then
    info "Installing with Zscaler certificate: ${CERT_PATH}"
    pip install --cert="${CERT_PATH}" -r requirements.txt
else
    info "Installing without specific certificate (standard pip install)."
    if ! pip install -r requirements.txt; then
        warn "Standard pip install failed. Trying with trusted hosts for PyPI..."
        pip install --trusted-host pypi.org --trusted-host files.pythonhosted.org -r requirements.txt
    fi
fi
info "Dependencies installed."

# --- PostgreSQL (pgvector) Setup with Docker ---
DB_CONTAINER_NAME="pgvector_postgres_aigovapi"
DB_PASSWORD="postgres"
DB_USER="postgres" # Added for clarity
DB_NAME="postgres"
DB_PORT="5433" # Local port mapped to container's 5432
DB_HOST="localhost" # Host for the application to connect to

info "Setting up PostgreSQL (pgvector) using Docker..."
if [ "$(docker ps -q -f name="^/${DB_CONTAINER_NAME}$")" ]; then
    info "PostgreSQL container '${DB_CONTAINER_NAME}' is already running."
elif [ "$(docker ps -aq -f status=exited -f name="^/${DB_CONTAINER_NAME}$")" ]; then
    info "PostgreSQL container '${DB_CONTAINER_NAME}' exists but is stopped. Starting it..."
    docker start "${DB_CONTAINER_NAME}"
else
    info "PostgreSQL container '${DB_CONTAINER_NAME}' not found. Creating and starting it..."
    docker run --name "${DB_CONTAINER_NAME}" \
        -e POSTGRES_USER="${DB_USER}" \
        -e POSTGRES_PASSWORD="${DB_PASSWORD}" \
        -e POSTGRES_DB="${DB_NAME}" \
        -p "${DB_PORT}:5432" \
        -d pgvector/pgvector:pg15 # Using pg15 as per project's docker-compose
    info "Waiting for PostgreSQL container to initialize (approx. 10-15 seconds)..."
    sleep 15 # Increased sleep time for robust startup
fi

info "Checking PostgreSQL connection..."
max_retries=6
retry_count=0
until docker exec "${DB_CONTAINER_NAME}" pg_isready -U "${DB_USER}" -d "${DB_NAME}" -h localhost -p 5432 -q; do
    retry_count=$((retry_count + 1))
    if [ ${retry_count} -ge ${max_retries} ]; then
        error "PostgreSQL container '${DB_CONTAINER_NAME}' did not become ready. Check Docker logs: docker logs ${DB_CONTAINER_NAME}"
    fi
    info "PostgreSQL not ready yet, retrying in 5 seconds... (Attempt ${retry_count}/${max_retries})"
    sleep 5
done
info "PostgreSQL container '${DB_CONTAINER_NAME}' is up and running on local port ${DB_PORT}."

# --- .env File Configuration ---
info "Configuring .env file..."
ENV_FILE=".env"
USER_SECRETS_FILE="user_secrets.env" # Optional file for user to store their secrets
DEFAULT_ENV="dev"
DEFAULT_LOG_LEVEL="INFO"
# Ensure this matches the driver used in your SQLAlchemy connection string (psycopg for postgresql+psycopg)
DEFAULT_POSTGRES_CONNECTION="postgresql+psycopg://${DB_USER}:${DB_PASSWORD}@${DB_HOST}:${DB_PORT}/${DB_NAME}"
DEFAULT_DATABASE_ECHO="False"

# Ask user about using mock providers - defaulting to YES for mocks
USE_MOCK_PROVIDERS_CHOICE="true" # Default to true (mock providers)
read -rp "Do you want to use MOCK LLM providers for local development? (Y/n): " use_mocks_input
if [[ "$use_mocks_input" == "n" || "$use_mocks_input" == "N" ]]; then
    USE_MOCK_PROVIDERS_CHOICE="false"
    info "LIVE LLM providers will be used. Ensure AWS/GCP credentials are configured if needed."
else
    info "MOCK LLM providers will be used (default)."
fi

# Source user_secrets.env if it exists to pre-fill variables
# These variables will be used by prompt_if_unset if already set in the environment
if [ -f "$USER_SECRETS_FILE" ]; then
    info "Sourcing secrets from $USER_SECRETS_FILE to pre-fill prompts..."
    set -a # Automatically export all variables subsequently set or modified
    # shellcheck source=/dev/null
    source "$USER_SECRETS_FILE"
    set +a
else
    warn "$USER_SECRETS_FILE not found. You will be prompted for required secrets if not using mocks or if they are not already in your environment."
fi

# Prompt for cloud provider secrets. Pass "true" as third arg to prompt_if_unset.
# These will be empty if mocks are used and user skips them.
prompt_if_unset "AWS_DEFAULT_REGION" "Enter your AWS Default Region (e.g., us-east-1)" "true"
prompt_if_unset "GOOGLE_APPLICATION_CREDENTIALS" "Enter path to GCP Service Account Key JSON file (e.g., /path/to/your/key.json)" "true"
prompt_if_unset "VERTEX_PROJECT_ID" "Enter your GCP Vertex AI Project ID" "true" # Added based on settings.py
# Model ARNs are now specifically part of settings.py structure
prompt_if_unset "BEDROCK_MODELS__CLAUDE_3_5_SONNET__ARN" "Enter Bedrock ARN for Claude 3.5 Sonnet" "true"
prompt_if_unset "BEDROCK_MODELS__LLAMA3211B__ARN" "Enter Bedrock ARN for Llama 3.2 11B (or similar, e.g., meta.llama3-8b-instruct-v1:0)" "true"
prompt_if_unset "BEDROCK_MODELS__COHERE_ENGLISH_V3__ARN" "Enter Bedrock ARN for Cohere Embed English v3" "true"

# Write to .env file
{
    echo "ENV=${ENV:-$DEFAULT_ENV}"
    echo "LOG_LEVEL=${LOG_LEVEL:-$DEFAULT_LOG_LEVEL}"
    echo ""
    echo "# Database Configuration - Uses psycopg driver"
    echo "DB_USER=${DB_USER}"
    echo "DB_PASS=${DB_PASSWORD}"
    echo "DB_ENDPOINT=${DB_HOST}"
    echo "DB_PORT=${DB_PORT}"
    echo "DB_NAME=${DB_NAME}"
    # POSTGRES_CONNECTION is derived in settings.py, but can be set explicitly too
    # echo "POSTGRES_CONNECTION=${POSTGRES_CONNECTION:-$DEFAULT_POSTGRES_CONNECTION}" # Explicitly set
    echo "DATABASE_ECHO=${DATABASE_ECHO:-$DEFAULT_DATABASE_ECHO}"
    echo ""
    echo "# Provider Configuration"
    echo "USE_MOCK_PROVIDERS=${USE_MOCK_PROVIDERS_CHOICE}"
    echo ""
    echo "# AWS Configuration (can be empty if USE_MOCK_PROVIDERS=true and not needed by other parts of app startup)"
    echo "AWS_DEFAULT_REGION=${AWS_DEFAULT_REGION}"
    # BEDROCK_ASSUME_ROLE is not in settings.py, so not prompting for it. Add if needed.
    echo ""
    echo "# GCP Vertex AI Configuration (can be empty if USE_MOCK_PROVIDERS=true)"
    echo "GOOGLE_APPLICATION_CREDENTIALS=${GOOGLE_APPLICATION_CREDENTIALS}"
    echo "VERTEX_PROJECT_ID=${VERTEX_PROJECT_ID}" # Added
    echo ""
    echo "# Bedrock Model ARNs (can be empty if USE_MOCK_PROVIDERS=true)"
    echo "BEDROCK_MODELS__CLAUDE_3_5_SONNET__ARN=${BEDROCK_MODELS__CLAUDE_3_5_SONNET__ARN}"
    echo "BEDROCK_MODELS__LLAMA3211B__ARN=${BEDROCK_MODELS__LLAMA3211B__ARN}"
    echo "BEDROCK_MODELS__COHERE_ENGLISH_V3__ARN=${BEDROCK_MODELS__COHERE_ENGLISH_V3__ARN}"
} > "$ENV_FILE"

info ".env file configured successfully."
if [[ "$USE_MOCK_PROVIDERS_CHOICE" == "false" ]]; then
    info "IMPORTANT: LIVE provider mode selected. Ensure your AWS and GCP SDKs are authenticated (e.g., aws configure, gcloud auth application-default login) and GOOGLE_APPLICATION_CREDENTIALS points to a valid key file."
else
    info "MOCK provider mode selected. Live AWS/GCP credentials/configurations in .env are not strictly required for LLM calls but ensure variables are set if the application expects them on startup for other reasons."
fi
info "Current .env file content:"
echo "--- .env START ---"
cat .env
echo "--- .env END ---"
echo ""

# --- Database Migrations ---
info "Running database migrations using Alembic..."
# Ensure .env is loaded for alembic if it relies on it (it does via app.config.settings)
python -m alembic upgrade head
info "Database migrations applied."

# --- Create Initial Admin User and API Key ---
info "Creating initial admin user and API key..."
# Use environment variables for default admin user if set, otherwise prompt
DEFAULT_ADMIN_EMAIL_FROM_ENV="${DEFAULT_ADMIN_EMAIL:-}"
DEFAULT_ADMIN_NAME_FROM_ENV="${DEFAULT_ADMIN_NAME:-}"

if [ -z "$DEFAULT_ADMIN_EMAIL_FROM_ENV" ]; then
    read -rp "Enter email for the initial admin user (e.g., admin@example.com): " ADMIN_EMAIL
else
    ADMIN_EMAIL="$DEFAULT_ADMIN_EMAIL_FROM_ENV"
    info "Using admin email from environment or default: $ADMIN_EMAIL"
fi
if [ -z "$DEFAULT_ADMIN_NAME_FROM_ENV" ]; then
    read -rp "Enter name for the initial admin user (e.g., Admin User): " ADMIN_NAME
else
    ADMIN_NAME="$DEFAULT_ADMIN_NAME_FROM_ENV"
    info "Using admin name from environment or default: $ADMIN_NAME"
fi

if [ -z "$ADMIN_EMAIL" ] || [ -z "$ADMIN_NAME" ]; then
    error "Admin email and name are required."
fi
info "Running create_admin_user.py with Email: $ADMIN_EMAIL, Name: $ADMIN_NAME"
echo "----------------------------------------------------------------------"

# Run the admin user creation script
ADMIN_CREATION_OUTPUT=$(python scripts/create_admin_user.py --email "$ADMIN_EMAIL" --name "$ADMIN_NAME")
echo "$ADMIN_CREATION_OUTPUT"
echo "----------------------------------------------------------------------"

# Extract the API key from the output
GENERATED_API_KEY=$(echo "$ADMIN_CREATION_OUTPUT" | grep "API Key:" | sed 's/.*API Key: //')
if [ -n "$GENERATED_API_KEY" ]; then
    warn "IMPORTANT: Your generated API Key is: $GENERATED_API_KEY"
    warn "Please save this key in a secure location. It will NOT be shown again."
else
    warn "Could not automatically extract the API key. Please check the output above from 'scripts/create_admin_user.py' and save your API key."
fi

# --- Generate setup_ssl_certs.sh if Zscaler was detected ---
if [ "$ZSCALER_DETECTED" = "true" ] && [ -n "$CERT_PATH" ]; then
    info "Generating setup_ssl_certs.sh for Zscaler..."
    cat > "setup_ssl_certs.sh" << EOF
#!/bin/bash
# SSL certificate configuration for Zscaler (generated by setup_macos.sh)

export SSL_CERT_FILE="${CERT_PATH}"
export REQUESTS_CA_BUNDLE="${CERT_PATH}"
export PYTHONHTTPSVERIFY=1 # Often helpful with corporate proxies

echo "SSL certificate environment variables configured for Zscaler:"
echo "  SSL_CERT_FILE=${CERT_PATH}"
echo "  REQUESTS_CA_BUNDLE=${CERT_PATH}"
echo "These settings will only be active in this terminal session."
echo "Source this script in new terminal sessions: source ./setup_ssl_certs.sh"
EOF
    chmod +x setup_ssl_certs.sh
    info "Created setup_ssl_certs.sh script. Source it in new terminals if needed: source ./setup_ssl_certs.sh"
else
    # If Zscaler not detected, ensure any old setup_ssl_certs.sh doesn't cause confusion
    if [ -f "setup_ssl_certs.sh" ]; then
        info "No Zscaler detected, but an old setup_ssl_certs.sh exists. You may remove it or ignore it."
    fi
fi


# --- Final Instructions ---
info "Setup complete!"
if [[ "$USE_MOCK_PROVIDERS_CHOICE" == "true" ]];then
    info "Application is configured to use MOCK LLM providers."
else
    info "Application is configured to use LIVE LLM providers."
fi

info "To run the FastAPI application using the virtual environment:"
info "1. Ensure your Docker PostgreSQL container ('${DB_CONTAINER_NAME}') is running."
info "2. Open a new terminal in this project root directory."
info "3. Activate the virtual environment: source .venv/bin/activate"
if [ "$ZSCALER_DETECTED" = "true" ] && [ -f "setup_ssl_certs.sh" ]; then
    info "4. If behind Zscaler, configure SSL certs: source ./setup_ssl_certs.sh"
    info "5. Run the application: python -m uvicorn app.main:app --reload --host 0.0.0.0 --port 8000"
    info "   (Note: 'fastapi dev' from your README might also work if uvicorn is configured in pyproject.toml scripts)"
else
    info "4. Run the application: python -m uvicorn app.main:app --reload --host 0.0.0.0 --port 8000"
    info "   (Note: 'fastapi dev' from your README might also work if uvicorn is configured in pyproject.toml scripts)"
fi

info ""
info "The API will typically be available at http://127.0.0.1:8000"
info "API documentation (Swagger UI) at http://127.0.0.1:8000/docs"
info "Use the generated API Key: ${GENERATED_API_KEY:-CHECK_ABOVE_OUTPUT} for testing."
info "To run integration tests, ensure the application is running and see tests/integration/README.md."
